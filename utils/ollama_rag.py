import os
import shutil
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.output_parsers import StrOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from utils.config import Config
from utils.db_full_schema import get_full_db_schema, search_db_metadata, get_all_table_names

# -----------------------------------------------------------------
# 1. ëª¨ë¸ ë° ì„ë² ë”© ì´ˆê¸°í™”
# -----------------------------------------------------------------
llm = ChatOllama(
    model="gpt-oss:20b-cloud",
    temperature=0.1, 
    base_url="http://localhost:11434"
)

embeddings = HuggingFaceEmbeddings(model_name="C:\\Users\\User\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large\\snapshots\\0dc5580a448e4284468b8909bae50fa925907bc5")

# -----------------------------------------------------------------
# 2. ëŒ€í™” ê¸°ë¡ ì €ì¥ì†Œ (In-Memory for Test)
# -----------------------------------------------------------------
store = {}

def get_session_history(session_id: str):
    """í…ŒìŠ¤íŠ¸ìš© ë©”ëª¨ë¦¬ ì €ì¥ì†Œ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)"""
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# -----------------------------------------------------------------
# 3. ì´ˆê¸°í™” í•¨ìˆ˜ (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)
# -----------------------------------------------------------------
# utils/ollama_rag.py

def initialize_vectorstore():
    """ì•± ì‹œì‘ ì‹œ ë²¡í„° ìŠ¤í† ì–´ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤."""
    print("ğŸš€ [ì´ˆê¸°í™”] DB ìŠ¤í‚¤ë§ˆ ë²¡í„° ìŠ¤í† ì–´ í™•ì¸ ì¤‘...")
    
    try:
        # 1. ë²¡í„° ìŠ¤í† ì–´ íŒŒì¼(index.faiss)ì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
        index_path = os.path.join(Config.SCHEMA_STORE_PATH, "index.faiss")

        if os.path.exists(Config.SCHEMA_STORE_PATH) and os.path.exists(index_path):
            print(f"âœ… [ì´ˆê¸°í™” ìŠ¤í‚µ] ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. (ê²½ë¡œ: {Config.SCHEMA_STORE_PATH})")
            print("   (â€» DB ë³€ê²½ ì‚¬í•­ì„ ë°˜ì˜í•˜ë ¤ë©´ 'data/schema_store' í´ë”ë¥¼ ì‚­ì œ í›„ ì¬ì‹œì‘í•˜ì„¸ìš”.)")
            return

        # 2. ì—†ìœ¼ë©´ ìƒì„± ë¡œì§ ìˆ˜í–‰
        print("âš¡ ê¸°ì¡´ ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. DB ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ ë° ë²¡í„°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        docs = get_full_db_schema()
        if not docs:
            print("âš ï¸ [ì´ˆê¸°í™” ì£¼ì˜] DBì—ì„œ ì¶”ì¶œëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"   - ì¶”ì¶œëœ DB ê°ì²´ ìˆ˜: {len(docs)}ê°œ")

        lc_docs = [Document(page_content=d["content"], metadata={"name": d["name"]}) for d in docs]
        
        splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)
        split_docs = splitter.split_documents(lc_docs)
        
        vectorstore = FAISS.from_documents(split_docs, embeddings)
        vectorstore.save_local(Config.SCHEMA_STORE_PATH)
        print("âœ… [ì´ˆê¸°í™” ì™„ë£Œ] DB ë²¡í„°í™” ë° ì €ì¥ ì„±ê³µ!")
        
    except Exception as e:
        print(f"âŒ [ì´ˆê¸°í™” ì‹¤íŒ¨] ì˜¤ë¥˜ ë°œìƒ: {e}")

# -----------------------------------------------------------------
# 4. ë²¡í„° ë¦¬íŠ¸ë¦¬ë²„ ê´€ë¦¬
# -----------------------------------------------------------------
def get_db_retriever():
    if os.path.exists(os.path.join(Config.SCHEMA_STORE_PATH, "index.faiss")):
        vectorstore = FAISS.load_local(Config.SCHEMA_STORE_PATH, embeddings, allow_dangerous_deserialization=True)
        return vectorstore.as_retriever(search_kwargs={"k": 10})
    else:
        print("âš ï¸ ë²¡í„° ìŠ¤í† ì–´ê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ˆê¸°í™” ì‹¤íŒ¨ ê°€ëŠ¥ì„±)")
        return None

# -----------------------------------------------------------------
# 5. í‚¤ì›Œë“œ ì¶”ì¶œìš© (ì˜ë„ íŒŒì•…)
# -----------------------------------------------------------------
def extract_keyword(question: str):
    prompt = f"""
    ë‹¹ì‹ ì€ DB ê²€ìƒ‰ ì¿¼ë¦¬ ì¶”ì¶œê¸°ì…ë‹ˆë‹¤.
    ì§ˆë¬¸: '{question}'
    
    1. ì‚¬ìš©ìê°€ íŠ¹ì • í…Œì´ë¸”ëª…, ì»¬ëŸ¼ëª…, ë˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ìš©ì–´(ì˜ˆ: MEP, ì¸ì‚¬, ê¸‰ì—¬ ë“±)ë¥¼ ì°¾ê³  ìˆë‹¤ë©´ ê·¸ 'í•µì‹¬ ë‹¨ì–´' í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    2. 'í…Œì´ë¸”', 'ëª©ë¡', 'ì „ì²´', 'ë³´ì—¬ì¤˜' ê°™ì€ ì¼ë°˜ì ì¸ ìš”ì²­ ë‹¨ì–´ëŠ” ë¬´ì‹œí•˜ì„¸ìš”.
    3. ê²€ìƒ‰í•  êµ¬ì²´ì  ëŒ€ìƒì´ ì—†ë‹¤ë©´ "FALSE"ë¼ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    
    Output example:
    - "MEP í…Œì´ë¸” ìˆì–´?" -> MEP
    - "ì „ì²´ í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸ ì¤˜" -> FALSE
    - "ì‚¬ìš©ì ì •ë³´ ì–´ë”” ìˆì–´?" -> ì‚¬ìš©ì
    """
    return llm.invoke(prompt).content.strip()

# -----------------------------------------------------------------
# 6. í†µí•© RAG ì‹¤í–‰ í•¨ìˆ˜ (Hybrid Search ì ìš©)
# -----------------------------------------------------------------
def rag_with_history(question: str, session_id: str = "default"):
    
    retrieved_context = ""
    
    # 1. [ìš°ì„ ìˆœìœ„ 1] í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ë„ íŒŒì•…)
    # ì§ˆë¬¸ì— íŠ¹ì • ëŒ€ìƒ(MEP, USER ë“±)ì´ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤.
    keyword = extract_keyword(question)
    
    # 2. ë¡œì§ ë¶„ê¸° ì²˜ë¦¬
    if keyword != "FALSE" and len(keyword) > 1:
        # (A) êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: "MEP í…Œì´ë¸” ì°¾ì•„ì¤˜", "MEPê°€ í¬í•¨ëœ ì „ì²´ í…Œì´ë¸”")
        print(f"ğŸ” ë©”íƒ€ë°ì´í„° ì¡°ê±´ ê²€ìƒ‰ ìˆ˜í–‰: '{keyword}'")
        meta_result = search_db_metadata(keyword)
        retrieved_context += f"\n[DB ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼ (í‚¤ì›Œë“œ: {keyword})]\n{meta_result}\n"
        
        # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ë²¡í„° ê²€ìƒ‰ë„ ë³‘í–‰ ê°€ëŠ¥ (Hybrid)
        retriever = get_db_retriever()
        if retriever:
            docs = retriever.invoke(question)
            vec_result = "\n\n".join([f"--- {d.metadata.get('name')} ---\n{d.page_content}" for d in docs])
            retrieved_context += f"\n[ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ (ìœ ì‚¬ë„ ê²€ìƒ‰)]\n{vec_result}\n"

    elif any(x in question for x in ["ì „ì²´ í…Œì´ë¸”", "ëª¨ë“  í…Œì´ë¸”", "í…Œì´ë¸” ëª©ë¡", "í…Œì´ë¸” ë¦¬ìŠ¤íŠ¸"]):
        # (B) ê²€ìƒ‰ì–´ëŠ” ì—†ëŠ”ë° 'ì „ì²´'ë¥¼ ë‹¬ë¼ê³  í•œ ê²½ìš° (ì˜ˆ: "ê·¸ëƒ¥ ì „ì²´ í…Œì´ë¸” ë‹¤ ë³´ì—¬ì¤˜")
        print("ğŸ’¡ ì¡°ê±´ ì—†ëŠ” ì „ì²´ ëª©ë¡ ì¡°íšŒ ìš”ì²­ ê°ì§€")
        retrieved_context = f"[ì „ì²´ í…Œì´ë¸” ëª©ë¡]\n{get_all_table_names()}"
        
    else:
        # (C) ê·¸ ì™¸ ì¼ë°˜ì ì¸ ì§ˆë¬¸ -> ë²¡í„° ê²€ìƒ‰ë§Œ ìˆ˜í–‰
        print("ğŸ“š ì¼ë°˜ RAG ê²€ìƒ‰ ìˆ˜í–‰")
        retriever = get_db_retriever()
        if retriever:
            docs = retriever.invoke(question)
            vec_result = "\n\n".join([f"--- {d.metadata.get('name')} ---\n{d.page_content}" for d in docs])
            retrieved_context += f"\n[ê´€ë ¨ ìŠ¤í‚¤ë§ˆ ì •ë³´ (ìœ ì‚¬ë„ ê²€ìƒ‰)]\n{vec_result}\n"

    system_prompt = """ë„ˆëŠ” Oracle Database ì „ë¬¸ê°€ì´ì ë°ì´í„° ë¶„ì„ê°€ë‹¤.
                        ì•„ë˜ ì œê³µëœ [ì°¸ê³  ì •ë³´]ì™€ [ëŒ€í™” ê¸°ë¡]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ë¼.
                        - [DB ë©”íƒ€ë°ì´í„° ê²€ìƒ‰ ê²°ê³¼]ê°€ ìˆë‹¤ë©´ ê·¸ ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ì´ë¦„ì„ ì •í™•íˆ ë‹µë³€í•˜ë¼.
                        - ì§ˆë¬¸ì´ íŠ¹ì • í…Œì´ë¸”ì´ë‚˜ ì»¬ëŸ¼ì„ ì°¾ê³  ìˆë‹¤ë©´, ì •í™•í•œ ì´ë¦„ì„ ì œì‹œí•˜ë¼.
                    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("system", "[ì°¸ê³  ì •ë³´]\n{context}"),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}"),
    ])

    chain = prompt | llm | StrOutputParser()

    chain_with_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="question",
        history_messages_key="chat_history",
    )

    print(f"ğŸ” ì§ˆë¬¸(Session={session_id}): {question}")
    
    final_context = retrieved_context if retrieved_context.strip() else "ì œê³µëœ ë¬¸ì„œë‚˜ DB ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤."
    
    answer = chain_with_history.invoke(
        {"question": question, "context": final_context},
        config={"configurable": {"session_id": session_id}}
    )
    
    return {
        "answer": answer
    }